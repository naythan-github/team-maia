================================================================================
SENTIMENT ANALYSIS MODEL COMPARISON REPORT
Generated: 2025-10-21 08:01:22
Validation Set Size: 100 comments
================================================================================

OVERALL RANKING (by accuracy):
--------------------------------------------------------------------------------
1. gemma2:9b: 78.0% (78/100), Avg Latency: 5498ms
2. llama3.1:8b: 73.0% (73/100), Avg Latency: 4028ms
3. mistral:7b: 69.0% (69/100), Avg Latency: 5424ms
4. llama3.2:3b: 59.0% (59/100), Avg Latency: 1625ms
5. keyword_baseline: 32.0% (32/100)

DETAILED METRICS BY MODEL:
================================================================================

Model: gemma2:9b
Accuracy: 78.0%
Avg Latency: 5498ms

Per-Class Metrics:
  Positive:
    Precision: 69.4% (TP: 25, FP: 11)
    Recall:    83.3% (FN: 5)
    F1 Score:  75.8%
  Negative:
    Precision: 80.0% (TP: 4, FP: 1)
    Recall:    80.0% (FN: 1)
    F1 Score:  80.0%
  Neutral:
    Precision: 82.8% (TP: 48, FP: 10)
    Recall:    82.8% (FN: 10)
    F1 Score:  82.8%
  Mixed:
    Precision: 100.0% (TP: 1, FP: 0)
    Recall:    14.3% (FN: 6)
    F1 Score:  25.0%
--------------------------------------------------------------------------------

Model: llama3.1:8b
Accuracy: 73.0%
Avg Latency: 4028ms

Per-Class Metrics:
  Positive:
    Precision: 75.9% (TP: 22, FP: 7)
    Recall:    73.3% (FN: 8)
    F1 Score:  74.6%
  Negative:
    Precision: 29.4% (TP: 5, FP: 12)
    Recall:    100.0% (FN: 0)
    F1 Score:  45.5%
  Neutral:
    Precision: 84.9% (TP: 45, FP: 8)
    Recall:    77.6% (FN: 13)
    F1 Score:  81.1%
  Mixed:
    Precision: 100.0% (TP: 1, FP: 0)
    Recall:    14.3% (FN: 6)
    F1 Score:  25.0%
--------------------------------------------------------------------------------

Model: mistral:7b
Accuracy: 69.0%
Avg Latency: 5424ms

Per-Class Metrics:
  Positive:
    Precision: 88.9% (TP: 16, FP: 2)
    Recall:    53.3% (FN: 14)
    F1 Score:  66.7%
  Negative:
    Precision: 50.0% (TP: 4, FP: 4)
    Recall:    80.0% (FN: 1)
    F1 Score:  61.5%
  Neutral:
    Precision: 71.9% (TP: 46, FP: 18)
    Recall:    79.3% (FN: 12)
    F1 Score:  75.4%
  Mixed:
    Precision: 30.0% (TP: 3, FP: 7)
    Recall:    42.9% (FN: 4)
    F1 Score:  35.3%
--------------------------------------------------------------------------------

Model: llama3.2:3b
Accuracy: 59.0%
Avg Latency: 1625ms

Per-Class Metrics:
  Positive:
    Precision: 66.7% (TP: 4, FP: 2)
    Recall:    13.3% (FN: 26)
    F1 Score:  22.2%
  Negative:
    Precision: 14.3% (TP: 1, FP: 6)
    Recall:    20.0% (FN: 4)
    F1 Score:  16.7%
  Neutral:
    Precision: 62.1% (TP: 54, FP: 33)
    Recall:    93.1% (FN: 4)
    F1 Score:  74.5%
  Mixed:
    Precision: 0.0% (TP: 0, FP: 0)
    Recall:    0.0% (FN: 7)
    F1 Score:  0.0%
--------------------------------------------------------------------------------

Model: keyword_baseline
Accuracy: 32.0%

Per-Class Metrics:
  Positive:
    Precision: 35.0% (TP: 14, FP: 26)
    Recall:    46.7% (FN: 16)
    F1 Score:  40.0%
  Negative:
    Precision: 10.0% (TP: 4, FP: 36)
    Recall:    80.0% (FN: 1)
    F1 Score:  17.8%
  Neutral:
    Precision: 70.0% (TP: 14, FP: 6)
    Recall:    24.1% (FN: 44)
    F1 Score:  35.9%
  Mixed:
    Precision: 0.0% (TP: 0, FP: 0)
    Recall:    0.0% (FN: 7)
    F1 Score:  0.0%
--------------------------------------------------------------------------------

RECOMMENDATION:
================================================================================
Best Model: gemma2:9b
Accuracy: 78.0%
Improvement over baseline: +46.0%

âœ… SIGNIFICANT IMPROVEMENT - Recommend switching to LLM-based sentiment