================================================================================
SENTIMENT ANALYSIS MODEL COMPARISON REPORT
Generated: 2025-10-21 09:39:53
Validation Set Size: 100 comments
================================================================================

OVERALL RANKING (by accuracy):
--------------------------------------------------------------------------------
1. gemma2:9b: 81.0% (81/100), Avg Latency: 5120ms
2. mistral:7b: 75.0% (75/100), Avg Latency: 4240ms
3. llama3.2:3b: 62.0% (62/100), Avg Latency: 1565ms
4. llama3.1:8b: 60.0% (60/100), Avg Latency: 6598ms
5. keyword_baseline: 32.0% (32/100)

DETAILED METRICS BY MODEL:
================================================================================

Model: gemma2:9b
Accuracy: 81.0%
Avg Latency: 5120ms

Per-Class Metrics:
  Positive:
    Precision: 80.6% (TP: 25, FP: 6)
    Recall:    83.3% (FN: 5)
    F1 Score:  82.0%
  Negative:
    Precision: 45.5% (TP: 5, FP: 6)
    Recall:    100.0% (FN: 0)
    F1 Score:  62.5%
  Neutral:
    Precision: 87.7% (TP: 50, FP: 7)
    Recall:    86.2% (FN: 8)
    F1 Score:  87.0%
  Mixed:
    Precision: 100.0% (TP: 1, FP: 0)
    Recall:    14.3% (FN: 6)
    F1 Score:  25.0%
--------------------------------------------------------------------------------

Model: mistral:7b
Accuracy: 75.0%
Avg Latency: 4240ms

Per-Class Metrics:
  Positive:
    Precision: 90.9% (TP: 20, FP: 2)
    Recall:    66.7% (FN: 10)
    F1 Score:  76.9%
  Negative:
    Precision: 40.0% (TP: 2, FP: 3)
    Recall:    40.0% (FN: 3)
    F1 Score:  40.0%
  Neutral:
    Precision: 81.0% (TP: 51, FP: 12)
    Recall:    87.9% (FN: 7)
    F1 Score:  84.3%
  Mixed:
    Precision: 20.0% (TP: 2, FP: 8)
    Recall:    28.6% (FN: 5)
    F1 Score:  23.5%
--------------------------------------------------------------------------------

Model: llama3.2:3b
Accuracy: 62.0%
Avg Latency: 1565ms

Per-Class Metrics:
  Positive:
    Precision: 57.1% (TP: 24, FP: 18)
    Recall:    80.0% (FN: 6)
    F1 Score:  66.7%
  Negative:
    Precision: 75.0% (TP: 3, FP: 1)
    Recall:    60.0% (FN: 2)
    F1 Score:  66.7%
  Neutral:
    Precision: 86.1% (TP: 31, FP: 5)
    Recall:    53.4% (FN: 27)
    F1 Score:  66.0%
  Mixed:
    Precision: 22.2% (TP: 4, FP: 14)
    Recall:    57.1% (FN: 3)
    F1 Score:  32.0%
--------------------------------------------------------------------------------

Model: llama3.1:8b
Accuracy: 60.0%
Avg Latency: 6598ms

Per-Class Metrics:
  Positive:
    Precision: 80.0% (TP: 4, FP: 1)
    Recall:    13.3% (FN: 26)
    F1 Score:  22.9%
  Negative:
    Precision: 0.0% (TP: 0, FP: 1)
    Recall:    0.0% (FN: 5)
    F1 Score:  0.0%
  Neutral:
    Precision: 59.6% (TP: 56, FP: 38)
    Recall:    96.6% (FN: 2)
    F1 Score:  73.7%
  Mixed:
    Precision: 0.0% (TP: 0, FP: 0)
    Recall:    0.0% (FN: 7)
    F1 Score:  0.0%
--------------------------------------------------------------------------------

Model: keyword_baseline
Accuracy: 32.0%

Per-Class Metrics:
  Positive:
    Precision: 35.0% (TP: 14, FP: 26)
    Recall:    46.7% (FN: 16)
    F1 Score:  40.0%
  Negative:
    Precision: 10.0% (TP: 4, FP: 36)
    Recall:    80.0% (FN: 1)
    F1 Score:  17.8%
  Neutral:
    Precision: 70.0% (TP: 14, FP: 6)
    Recall:    24.1% (FN: 44)
    F1 Score:  35.9%
  Mixed:
    Precision: 0.0% (TP: 0, FP: 0)
    Recall:    0.0% (FN: 7)
    F1 Score:  0.0%
--------------------------------------------------------------------------------

RECOMMENDATION:
================================================================================
Best Model: gemma2:9b
Accuracy: 81.0%
Improvement over baseline: +49.0%

âœ… SIGNIFICANT IMPROVEMENT - Recommend switching to LLM-based sentiment