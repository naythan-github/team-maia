#!/usr/bin/env python3
"""
Test suite for Weekly Narrative Synthesizer.

Tests narrative generation, error handling, performance, and edge cases.
"""

import pytest
import sys
import json
import tempfile
from pathlib import Path
from datetime import datetime, timedelta
from unittest.mock import Mock, patch, MagicMock

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent / 'claude' / 'tools'))

from weekly_narrative_synthesizer import WeeklyNarrativeSynthesizer


class TestNarrativeGeneration:
    """Test basic narrative generation functionality."""

    def test_generate_empty_week_narrative(self):
        """Test generation when no shareable journeys exist."""
        synthesizer = WeeklyNarrativeSynthesizer()

        # Mock logger to return empty list
        synthesizer.logger.get_week_journeys = Mock(return_value=[])

        narrative = synthesizer.generate_weekly_narrative()

        assert "No Shareable Journeys This Week" in narrative
        assert "Discovering What's Possible with Maia" in narrative
        assert "Generated by Maia" in narrative

    def test_generate_single_journey_narrative(self):
        """Test generation with one journey."""
        synthesizer = WeeklyNarrativeSynthesizer()

        # Mock journey data
        journey = {
            'journey_id': 'test-123',
            'problem_description': 'Need to migrate 50 firewalls',
            'initial_question': 'How do I migrate these configs?',
            'maia_options_presented': '["Manual (80h)", "Semi-auto (20h)", "API-driven (5h)"]',
            'user_refinement_quote': 'Validate API access first',
            'agents_used': '[{"agent": "SRE Principal Engineer", "rationale": "API validation"}]',
            'deliverables': '[{"type": "file", "name": "tool.py", "description": "API tool", "size": "10KB"}]',
            'business_impact': '95% time reduction',
            'meta_learning': 'Assumption Testing pattern',
            'iteration_count': 2
        }

        synthesizer.logger.get_week_journeys = Mock(return_value=[journey])

        narrative = synthesizer.generate_weekly_narrative()

        # Verify key sections present
        assert "Journey 1:" in narrative
        assert "The Problem" in narrative
        assert "Our Conversation Started" in narrative
        assert "The Impact" in narrative
        assert "What This Shows You Can Do" in narrative
        assert "This Week's Pattern" in narrative
        assert "New Ways of Working" in narrative

    def test_generate_multiple_journeys_narrative(self):
        """Test generation with multiple journeys."""
        synthesizer = WeeklyNarrativeSynthesizer()

        journeys = [
            {
                'problem_description': 'Problem 1',
                'initial_question': 'Question 1',
                'maia_options_presented': '["Option A", "Option B"]',
                'user_refinement_quote': 'Refinement 1',
                'agents_used': '[{"agent": "Agent 1", "rationale": "Reason 1"}]',
                'deliverables': '[]',
                'business_impact': 'Impact 1',
                'meta_learning': 'Pattern 1',
                'iteration_count': 1
            },
            {
                'problem_description': 'Problem 2',
                'initial_question': 'Question 2',
                'maia_options_presented': '["Option C", "Option D"]',
                'user_refinement_quote': 'Refinement 2',
                'agents_used': '[{"agent": "Agent 2", "rationale": "Reason 2"}]',
                'deliverables': '[]',
                'business_impact': 'Impact 2',
                'meta_learning': 'Pattern 2',
                'iteration_count': 3
            }
        ]

        synthesizer.logger.get_week_journeys = Mock(return_value=journeys)

        narrative = synthesizer.generate_weekly_narrative()

        assert "Journey 1:" in narrative
        assert "Journey 2:" in narrative
        assert "2 problem-solving journeys" in narrative


class TestJSONParsing:
    """Test JSON field parsing edge cases."""

    def test_parse_json_string(self):
        """Test parsing JSON string."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._parse_json_field('["item1", "item2"]')
        assert result == ["item1", "item2"]

    def test_parse_json_list(self):
        """Test parsing already-parsed list."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._parse_json_field(["item1", "item2"])
        assert result == ["item1", "item2"]

    def test_parse_json_dict(self):
        """Test parsing dict (converts to list)."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._parse_json_field({"key": "value"})
        assert result == [{"key": "value"}]

    def test_parse_malformed_json(self):
        """Test graceful handling of malformed JSON."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._parse_json_field('{"invalid json')
        assert result == []

    def test_parse_none_value(self):
        """Test handling of None value."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._parse_json_field(None)
        assert result == []

    def test_parse_empty_string(self):
        """Test handling of empty string."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._parse_json_field('')
        assert result == []


class TestConversationalFormatting:
    """Test conversational tone formatting."""

    def test_make_conversational_problem_without_you(self):
        """Test problem formatting when 'you' not present."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._make_conversational_problem("Need to migrate configs")
        assert result == "You had need to migrate configs. "

    def test_make_conversational_problem_with_you(self):
        """Test problem formatting when 'you' already present."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._make_conversational_problem("You needed to migrate configs")
        assert result == "You needed to migrate configs"

    def test_format_options_empty(self):
        """Test options formatting with empty list."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._format_options([])
        assert result == "Maia explored several approaches."

    def test_format_options_single(self):
        """Test options formatting with single option."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._format_options(["Manual approach"])
        assert "Maia explored these paths:" in result
        assert "→ Manual approach" in result

    def test_format_options_multiple(self):
        """Test options formatting with multiple options."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._format_options(["Option A", "Option B", "Option C"])
        assert "→ Option A" in result
        assert "→ Option B" in result
        assert "→ Option C" in result

    def test_format_options_limit_to_five(self):
        """Test options limited to 5 maximum."""
        synthesizer = WeeklyNarrativeSynthesizer()

        options = ["Opt1", "Opt2", "Opt3", "Opt4", "Opt5", "Opt6", "Opt7"]
        result = synthesizer._format_options(options)

        # Should only show first 5
        assert "→ Opt1" in result
        assert "→ Opt5" in result
        assert "→ Opt6" not in result

    def test_format_refinement_empty(self):
        """Test refinement formatting with empty string."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._format_refinement('')
        assert result == ""

    def test_format_refinement_with_quote(self):
        """Test refinement formatting with quote."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._format_refinement("Let's validate API first")
        assert "You Refined the Approach" in result
        assert '"Let\'s validate API first"' in result
        assert "Smart call" in result


class TestAgentFormatting:
    """Test agent engagement formatting."""

    def test_format_single_agent(self):
        """Test formatting with single agent."""
        synthesizer = WeeklyNarrativeSynthesizer()

        agents = [{"agent": "SRE Principal Engineer", "rationale": "API validation"}]
        result = synthesizer._format_agents(agents)

        assert "Built a Specialist to Help" in result
        assert "SRE Principal Engineer" in result
        assert "api validation" in result.lower()

    def test_format_multiple_agents(self):
        """Test formatting with multiple agents."""
        synthesizer = WeeklyNarrativeSynthesizer()

        agents = [
            {"agent": "SRE Agent", "rationale": "Reason 1"},
            {"agent": "Data Agent", "rationale": "Reason 2"}
        ]
        result = synthesizer._format_agents(agents)

        assert "Worked with Multiple Specialists" in result
        assert "SRE Agent" in result
        assert "Data Agent" in result

    def test_format_agents_empty(self):
        """Test formatting with no agents."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._format_agents([])
        assert result == ""


class TestDeliverablesFormatting:
    """Test deliverables formatting."""

    def test_format_deliverables_empty(self):
        """Test with no deliverables."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._format_deliverables([])
        assert result == ""

    def test_format_deliverables_single(self):
        """Test with single deliverable."""
        synthesizer = WeeklyNarrativeSynthesizer()

        deliverables = [{
            "type": "file",
            "name": "tool.py",
            "description": "API tool",
            "size": "10KB"
        }]
        result = synthesizer._format_deliverables(deliverables)

        assert "What Got Delivered" in result
        assert "tool.py" in result
        assert "API tool" in result
        assert "10KB" in result

    def test_format_deliverables_limit_to_five(self):
        """Test deliverables limited to 5."""
        synthesizer = WeeklyNarrativeSynthesizer()

        deliverables = [
            {"name": f"file{i}.py"} for i in range(10)
        ]
        result = synthesizer._format_deliverables(deliverables)

        assert "file0.py" in result
        assert "file4.py" in result
        assert "file5.py" not in result


class TestStatsGeneration:
    """Test statistics section generation."""

    def test_stats_single_journey(self):
        """Test stats with single journey."""
        synthesizer = WeeklyNarrativeSynthesizer()

        journeys = [{
            'iteration_count': 2,
            'agents_used': '[{"agent": "SRE Agent"}]'
        }]

        result = synthesizer._generate_stats_section(journeys)

        assert "1 problem-solving journey" in result
        assert "Average refinements: 2.0 iterations" in result
        assert "SRE Agent: 1" in result

    def test_stats_multiple_journeys(self):
        """Test stats with multiple journeys."""
        synthesizer = WeeklyNarrativeSynthesizer()

        journeys = [
            {'iteration_count': 1, 'agents_used': '[{"agent": "Agent A"}]'},
            {'iteration_count': 3, 'agents_used': '[{"agent": "Agent B"}]'},
            {'iteration_count': 2, 'agents_used': '[{"agent": "Agent A"}]'}
        ]

        result = synthesizer._generate_stats_section(journeys)

        assert "3 problem-solving journeys" in result
        assert "Average refinements: 2.0 iterations" in result
        assert "Agent A: 2" in result
        assert "Agent B: 1" in result

    def test_stats_division_by_zero_protection(self):
        """Test handling of empty iteration list."""
        synthesizer = WeeklyNarrativeSynthesizer()

        journeys = [
            {'agents_used': '[]'}  # No iteration_count
        ]

        result = synthesizer._generate_stats_section(journeys)
        assert "Average refinements: 1.0" in result  # Default value


class TestMetaLearning:
    """Test meta-learning extraction."""

    def test_meta_learning_no_patterns(self):
        """Test with no meta-learning patterns."""
        synthesizer = WeeklyNarrativeSynthesizer()

        journeys = [
            {'meta_learning': ''},
            {'meta_learning': None}
        ]

        result = synthesizer._generate_meta_learning_section(journeys)
        assert "No explicit patterns documented" in result

    def test_meta_learning_single_pattern(self):
        """Test with single pattern."""
        synthesizer = WeeklyNarrativeSynthesizer()

        journeys = [
            {'meta_learning': 'TDD methodology ensures quality'}
        ]

        result = synthesizer._generate_meta_learning_section(journeys)
        assert "TDD methodology ensures quality" in result
        assert "Try this next time" in result

    def test_meta_learning_duplicate_patterns(self):
        """Test deduplication of patterns."""
        synthesizer = WeeklyNarrativeSynthesizer()

        journeys = [
            {'meta_learning': 'Pattern A'},
            {'meta_learning': 'Pattern A'},
            {'meta_learning': 'Pattern B'}
        ]

        result = synthesizer._generate_meta_learning_section(journeys)

        # Should only show unique patterns
        pattern_count = result.count("**Pattern**:")
        assert pattern_count == 2

    def test_extract_takeaway_assumption(self):
        """Test takeaway extraction for assumption patterns."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._extract_takeaway("Assumption Testing pattern")
        assert "riskiest assumption" in result

    def test_extract_takeaway_automation(self):
        """Test takeaway extraction for automation patterns."""
        synthesizer = WeeklyNarrativeSynthesizer()

        result = synthesizer._extract_takeaway("Automation discovery pattern")
        assert "automation options" in result


class TestFileOutput:
    """Test file writing functionality."""

    def test_save_to_file(self):
        """Test saving narrative to file."""
        synthesizer = WeeklyNarrativeSynthesizer()
        synthesizer.logger.get_week_journeys = Mock(return_value=[])

        with tempfile.TemporaryDirectory() as tmpdir:
            output_path = Path(tmpdir) / "test_narrative.md"

            narrative = synthesizer.generate_weekly_narrative(str(output_path))

            assert output_path.exists()
            content = output_path.read_text()
            assert content == narrative
            assert "No Shareable Journeys" in content

    def test_create_parent_directories(self):
        """Test automatic parent directory creation."""
        synthesizer = WeeklyNarrativeSynthesizer()
        synthesizer.logger.get_week_journeys = Mock(return_value=[])

        with tempfile.TemporaryDirectory() as tmpdir:
            output_path = Path(tmpdir) / "subdir1" / "subdir2" / "narrative.md"

            narrative = synthesizer.generate_weekly_narrative(str(output_path))

            assert output_path.exists()
            assert output_path.parent.parent.exists()


class TestErrorHandling:
    """Test error handling and edge cases."""

    def test_handle_logger_failure(self):
        """Test graceful handling when logger fails."""
        synthesizer = WeeklyNarrativeSynthesizer()
        synthesizer.logger.get_week_journeys = Mock(side_effect=Exception("DB error"))

        # Should handle gracefully and return empty week narrative
        narrative = synthesizer.generate_weekly_narrative()
        assert "No Shareable Journeys This Week" in narrative
        assert narrative is not None

    def test_handle_missing_journey_fields(self):
        """Test handling of journeys with missing fields."""
        synthesizer = WeeklyNarrativeSynthesizer()

        # Journey with minimal fields
        journey = {
            'journey_id': 'test-minimal'
        }

        synthesizer.logger.get_week_journeys = Mock(return_value=[journey])

        # Should not crash
        narrative = synthesizer.generate_weekly_narrative()
        assert "Journey 1:" in narrative


class TestPerformance:
    """Test performance requirements."""

    def test_performance_10_journeys(self):
        """Test generation completes in <5 minutes for 10 journeys."""
        import time

        synthesizer = WeeklyNarrativeSynthesizer()

        # Create 10 mock journeys
        journeys = []
        for i in range(10):
            journeys.append({
                'problem_description': f'Problem {i}',
                'initial_question': f'Question {i}',
                'maia_options_presented': '["Opt1", "Opt2", "Opt3"]',
                'user_refinement_quote': f'Refinement {i}',
                'agents_used': '[{"agent": "Agent", "rationale": "Reason"}]',
                'deliverables': '[{"name": "file.py", "description": "Tool"}]',
                'business_impact': f'Impact {i}',
                'meta_learning': f'Pattern {i}',
                'iteration_count': 2
            })

        synthesizer.logger.get_week_journeys = Mock(return_value=journeys)

        start = time.time()
        narrative = synthesizer.generate_weekly_narrative()
        duration = time.time() - start

        # Should complete in <5 minutes (300 seconds)
        assert duration < 300, f"Generation took {duration}s, expected <300s"

        # Should also be reasonable (under 5 seconds for this simple case)
        assert duration < 5, f"Generation took {duration}s, expected <5s for in-memory operation"

        # Verify all journeys present
        for i in range(10):
            assert f"Journey {i+1}:" in narrative


if __name__ == '__main__':
    pytest.main([__file__, '-v'])
