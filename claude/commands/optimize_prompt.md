# Optimize Prompt Command

## Purpose
Transform weak or ineffective prompts into high-performance versions using proven engineering techniques.

## Usage
```
optimize_prompt <original_prompt> [desired_outcomes] [constraints]
```

## Process

### 1. Intent Extraction
- Identify true user goals beyond surface request
- Clarify desired output format and structure
- Understand context and use case scenarios
- Define success criteria and quality measures

### 2. Engineering Techniques Applied
- **Chain-of-Thought**: Break complex tasks into steps
- **Few-Shot Examples**: Provide concrete demonstrations
- **Role Definition**: Establish clear AI persona and expertise
- **Context Hierarchy**: Organize information by importance
- **Constraint Specification**: Define boundaries and limitations
- **Output Formatting**: Structure response requirements

### 3. Optimization Strategies
- **Clarity Enhancement**: Remove ambiguity and vague terms
- **Specificity Increase**: Add precise requirements and parameters
- **Context Loading**: Include relevant background information
- **Error Prevention**: Anticipate and prevent common mistakes
- **Token Efficiency**: Maximize impact per token used

## Output Format

```markdown
# Prompt Optimization Report

## Original Prompt Analysis
**Prompt**: [Original text]
**Primary Issues**: [Key problems identified]
**Improvement Opportunity**: [Potential impact]

## Optimization Strategy
**Techniques Applied**: [List of methods used]
**Focus Areas**: [What was prioritized]
**Target Outcomes**: [Expected improvements]

## Optimized Prompt

### Version A (Recommended)
[Primary optimized version]

**Key Improvements**:
- [Specific enhancements made]
- [Why these changes improve performance]

### Version B (Alternative)
[Alternative approach for A/B testing]

**Differences**:
- [How this differs from Version A]
- [When to use this variation]

## Comparison Analysis

| Aspect | Original | Version A | Version B |
|--------|----------|-----------|-----------|
| Clarity | [Score] | [Score] | [Score] |
| Specificity | [Score] | [Score] | [Score] |
| Context | [Score] | [Score] | [Score] |
| Efficiency | [Score] | [Score] | [Score] |

## Implementation Guide

### Usage Context
- **Best For**: [Optimal use cases]
- **Avoid When**: [Situations where other approaches are better]
- **Customization**: [How to adapt for specific needs]

### Testing Recommendations
1. **Test Scenarios**: [Specific situations to validate]
2. **Success Metrics**: [How to measure effectiveness]
3. **Iteration Points**: [Where to refine further]

### Maintenance
- **Update Triggers**: [When to revise the prompt]
- **Version Control**: [How to track changes]
- **Performance Monitoring**: [Ongoing quality checks]
```

## Advanced Techniques

### Meta-Prompting
- Self-improving prompts that refine their own output
- Recursive optimization for complex tasks
- Dynamic adaptation based on context

### Prompt Chaining
- Breaking complex tasks into linked prompts
- Maintaining context across prompt sequences
- Optimizing handoffs between prompt stages

### Template Engineering
- Creating flexible, reusable prompt structures
- Parameterized prompts for systematic variation
- Modular components for complex workflows

## Quality Assurance
- Always provide multiple variations for testing
- Include specific success criteria
- Offer clear implementation guidance
- Explain the rationale behind each optimization